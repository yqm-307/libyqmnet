# 打卡记录

## 前言：
        大三菜鸡，正在实习，趁空档学习一下网络编程。刚入门就看网上推荐看陈硕大佬的 muduo 网络库，
    所以就想着看一遍，并想办法优化或者复刻。在这里记录自己每天的感想和进度。

## 2月4日
        开始动笔写这个的东西的时候，muduo已经开始看，并且写了一些组件了。现在就是已经完成了定时器、
    日志。因为是自实现的定时器，而不是 timefd 那个linux 系统库的定时器。
    
#### 定时器
        timefd的话，好像是一个内存中的文件，这个文件也会可读，触发可读事件就是超时了。所以很适合在
    select、poll、epoll中使用。而且muduo的Epoller刚好将所有事件放在一起管理，这样所有事件（包括各种回调和定时器事件）都会在EventLoop中处理了。

        自己实现的定时器就很简单，依靠的是c++11 的std::thread 中的 sleep_for 函数，将线程休眠，苏醒后就触发回调。

#### 定时器队列
        其实我更愿意称为定时事件队列，因为看了muduo里面的定时器后发现，其实整个队列里面最重要的结
    构就是一个有序队列（平衡二叉树），里面存的键值对就是TimerOutCallBack和timestamp。按照
    timestamp排序，也就是按照时间排序。但是内部只有一个定时器在工作，这是个什么原理呢？

        就是有定时事件的时候就放进队列排队，然后使用定时器，定时器到时就会抛给EventLoop中进行处理。接着，定时器开始做队列中的下一个任务。


#### 日志
        这个没什么好说的，就是简单的做了一个队列化。提供一个异步接口，写日志不会阻塞在write操作上
    ，因为开了个磁盘IO线程不断写。


## 2月8日
        buffer的设计遵循了陈硕大佬的设计风格。缓冲区内有一个动态数组 vector<char> 作
    为byte流，另外两个readindex和writeindex，代表当前读和当前写的字节数。
    
    这个buffer在写的时候，是这样的
    初始状态：
    [------------------]
    ^
    read
    write
    
    写入字节：
    [------------------]
    ^       ^
    read    write

    读取字节：
    [------------------]
            ^    ^
            read write

    向前移动：
    [------------------]
    ^    ^
    read write


## 2月11日
        今天看我自己写的定时器队列，其实和陈硕大佬写的不一样。muduo原本的定时器使用的是timerfd，可以配
    合epoll使用，根据事件触发，不需要轮询等待下一个定时器事件。
        但是我自己写的就比较笨了，我是自己尝试实现的timer，采用的是thread::sleep_for()。而且今天发现
    我的线程还不可以复用，就是每有一个事件发生就会开一个线程，用完销毁，所以销毁和创建线程可以通过轮询替
    代。但是效率是否会提高还需要等待测试
        muduo对于周期性任务，执行完毕后会插入金timerqueue，确实牛皮，我想了半天都没想到怎么解决一个定时
    事件的问题。

## 2月14日
        看了EventLoop和Channel，梳理好了他们之间的关系。Channel有点不太懂，大致是对一个事件及其相关信
    息的封装。
        EventLoop就是主要的事件循环。但是不是这个loop不是一直出于工作状态，如果闲置的话会sleep，等待任务
    使用了eventfd来做通信，外部可以wakeup和sleep这个循环。
        同时修复了timerqueue测试案例出现bug的问题。

## 2月15日
        决定修改timerqueue，将它和eventloop分离。效率上来说不会太差，但是逻辑上可能更复杂。


## 2月16日
        给logger出队操作加锁，之前以为不加锁没影响，但是肯定还是要加锁的，之前测试开100个线程没问题，现
    在重新测试开1000个线程竞争就激烈了
        今天在研究cmake，遇到问题：没法编译通过程序

## 2月20日
        线程池大致完成，开启固定数量线程，线程根据任务队列中数据是否空阻塞，如果有新的task加入，就唤醒一个
    线程。但是遇到了奇怪的bug，暂时定位在Thread中的IsBlock和Block函数。


## 2月21日
        线程池bug已经解决，问题是因为有新任务到达时唤醒thread的时候调用isBlock出现问题，我用gdb单步调试，
    发现是空指针问题。因为我使用vector保存Thread* ，但是初始化的时候使用的是for_each 遍历vector。但是忘
    记给vector赋初始值了，后来改成push_back就没问题了。
        EventLoop大致没有了问题，现在需要开始封装Acceptor和TcpConnection，Acceptor负责监听和新连接到达
    时的回调，TcpConnection负责数据收发和回调。
        当前线程挂起和唤醒，都是立即的，如果改成有个缓冲时间可能会好很多。这样就不会频繁的调用notify和wait
        但是如果task入队快于线程池处理，就不会频繁的阻塞。所以还是不改了

## 2月26日
        我是傻逼，有个if后面加了引号坑了我一天，我超

## 2月28日
        epoll出现了问题，可能是sockfd没有设置复用，回学校再研究一下。今天调试一下看看怎么回事，初步定位一下
    回学校再详细看。准备开润。


## 3月5日
        编写了一个echo例程，网络库基础功能测试结束。重写cmake，将网络库编译成静态库，并编写example的cmake-
    list
        看了看shell脚本的语法，有点怪，写起来细节非常多
        昨天看了一天MySQL，速成一下，几天就可以了

## 3月10日
        看完了mysql，网络库还是有一些bug，有时间定位一下问题。然后看一下redis，这个网络库也只是练手用的，准
    备学asio了，毕竟要学会使用一个成熟的网络库。

## 3月17日
        log部分有些问题，程序崩溃原因是不同进程尝试打开一个文件，再尝试对一个文件写的时候就核心转储了。于是重
    写了log的构造，getinstance()创建单例的时候指定文件名
        
        log解决了之后，TcpClient部分也出现了问题，connect失败，有时间需要解决一下。
        
        开始编写单元测试程序，今天写了thread和threadpool

## 3月23日
        最近在看boost、asio和libco，稍微了解了一下基础用法，等后续有时间看看源码。
        
        今天发现了buffer有bug，要先做好单元测试，确保每个组件都没有大问题。

        网络库暂时放一放，先润去写语音服务器了

## 3月31日
        咕咕~